# ðŸ“š LangChain Runnables and Runnable Primitives â€“ Detailed Notes

---

## ðŸ” Introduction & Motivation

- **Video Continuation:** Focuses on _Runnables_, which standardize execution of all LangChain components.
- **Recap:** Previous videos covered chains, prompts, models, parsers, and retrieversâ€”now shifting to execution model (`invoke`-based abstraction).

---

## ðŸ¤© Problem with Early LangChain Components

- Components had **non-standard methods** like:
  - `.format()`
  - `.predict()`
  - `.parse()`
  - `.get_relevant_documents()`
- âŒ Difficult to chain and integrate in workflows.

### âœ… Solution: `Runnable` Abstract Class

- Introduced **standard **``** method**.
- All LangChain components now inherit from `Runnable`.
- Ensures **consistency and composability** across workflows.

---

## ðŸ§  Two Categories of Runnables

### 1. **Task-Specific Runnables**

- Designed for **specific operations**.
  - Prompt Templates
  - LLMs (like `ChatOpenAI`)
  - Parsers (e.g. `StrOutputParser`)
  - Retrievers

### 2. **Runnable Primitives**

- Low-level **workflow orchestration tools**:
  - `RunnableSequence`
  - `RunnableParallel`
  - `RunnableBranch`
  - `RunnableLambda`
  - `RunnablePassthrough`

---

## ðŸ”— `RunnableSequence`: Sequential Execution

### âž• Purpose:

Connect multiple runnables **in order**.

### ðŸ” Example:

- Input â†’ Prompt â†’ LLM â†’ Parser â†’ Output
- Extended version:
  - Joke â†’ Explain Joke (multi-step chaining)

### ðŸ”§ Syntax:

```python
chain = RunnableSequence([
    prompt,
    model,
    parser
])
```

---

## ðŸŒ `RunnableParallel`: Parallel Execution

### ðŸš€ Purpose:

Run **multiple chains concurrently** with the same input.

### ðŸ” Example:

Generate both:

- Tweet
- LinkedIn Post from same topic input.

### ðŸ”§ Syntax:

```python
chain = RunnableParallel({
    "tweet": tweet_chain,
    "linkedin": linkedin_chain
})
```

- Output is a dictionary with all results.

---

## ðŸ”„ `RunnablePassthrough`: Identity Runnable

### ðŸ’¡ Purpose:

Pass input **as-is** to the next step.

### ðŸ” Example:

Used to print both:

- Original joke
- Its explanation

### ðŸ”§ Usage:

```python
from langchain_core.runnables import RunnablePassthrough
pt = RunnablePassthrough()
```

---

## ðŸ”¢ `RunnableLambda`: Custom Python Functions

### ðŸš€ Purpose:

Convert **any Python function** into a Runnable.

### ðŸ” Example:

- Clean messy user text (HTML, punctuation, emojis)
- Count words in LLM output

### ðŸ”§ Syntax:

```python
word_count_fn = lambda x: len(x.split())
word_counter = RunnableLambda(word_count_fn)
```

---

## âš–ï¸ `RunnableBranch`: Conditional Logic

### ðŸš€ Purpose:

Create **if-else** style branching logic in workflows.

### ðŸ” Example:

- Generate report â†’ If >500 words â†’ Summarize
- Else â†’ Print as-is

### ðŸ”§ Syntax:

```python
RunnableBranch([
  (lambda x: len(x.split()) > 500, summarize_chain),
  (lambda x: True, print_chain)  # default case
])
```

---

## ðŸ”„ LCEL: LangChain Expression Language

### âœ… Purpose:

Declarative syntax to build chains using the **pipe (**``**) operator**.

### ðŸ”§ Example:

```python
chain = prompt | model | parser
```

- Improves **readability and simplicity**.
- Currently supports **sequential** chains.

---

## ðŸŒŸ Summary

| Runnable Primitive  | Purpose                        | Use Case Example                    |
| ------------------- | ------------------------------ | ----------------------------------- |
| RunnableSequence    | Connect runnables sequentially | Joke â†’ Explanation                  |
| RunnableParallel    | Run chains in parallel         | Tweet + LinkedIn                    |
| RunnablePassthrough | Pass data as-is                | Print original + transformed output |
| RunnableLambda      | Add custom Python logic        | Word count, text cleaning           |
| RunnableBranch      | Conditional logic (if-else)    | Summarize if long, else print       |

> âœ… Understanding runnables is key to building robust, modular, and scalable AI workflows in LangChain.

| Aspect              | **Chains** (Old Approach)                                                 | **Runnables** (Modern & Standardized)                                                                       |              |
| ------------------- | ------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------- | ------------ |
| **Definition**      | Abstraction to connect multiple components in LangChain.                  | A _standard interface_ for any component (LLM, Prompt, etc.) to ensure consistent behavior via `.invoke()`. |              |
| **Flexibility**     | Limited to predefined patterns (like Sequential, Simple Chains).          | Highly flexible: support sequential, parallel, conditional, and custom logic using primitives.              |              |
| **Standardization** | Components used different method names (`.format()`, `.predict()`, etc.). | All components use `.invoke()` for a unified interface.                                                     |              |
| **Composability**   | Difficult to compose complex workflows (needed manual wiring).            | Easily composable into pipelines using primitives like `RunnableSequence`, `RunnableParallel`, etc.         |              |
| **Extensibility**   | Custom chains required more boilerplate code.                             | Runnables allow wrapping Python logic (with `RunnableLambda`) or branching (`RunnableBranch`) with ease.    |              |
| **Syntax Style**    | Imperative and class-based setup.                                         | Supports declarative chaining with **LCEL** using \`                                                        | \` operator. |
| **Evolution**       | Foundation for early LangChain demos.                                     | Backbone of modern LangChain apps â€” modular, robust, and scalable.                                          |              |
