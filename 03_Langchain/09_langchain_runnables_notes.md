# ðŸ“˜ LangChain Runnables - Complete Conceptual Notes

## ðŸŽ¬ Introduction to LangChain and Runnables
- Nitesh introduces the LangChain playlist and focuses on a core concept called **Runnables**.
- Recap of earlier topics: chains like sequential, parallel, and conditional.
- Emphasizes Runnables as foundational units that make chains work effectively in LangChain.

---

## ðŸ“… Background: Rise of LLM Apps and LangChain Motivation
### ðŸ“ˆ 2022 and the OpenAI API Boom
- Public release of ChatGPT and OpenAI's API.
- Explosion in developer interest to build **LLM-based applications**.
- LangChain identified an opportunity to build a framework simplifying this.

### ðŸ§© Problem: Fragmented APIs
- Each LLM provider (OpenAI, Anthropic, Google) had different APIs.
- LangChain created a **unified interface** to interact with any LLM API seamlessly.

### ðŸ’¡ Insight: LLM Calls are Just One Part
- Example: Building a PDF reader isnâ€™t just about sending a query to an LLM.
- Additional steps: Load documents â†’ Split â†’ Embed â†’ Store â†’ Retrieve â†’ Query.

---

## ðŸ”§ LangChain Components (Modular Lego Blocks)
- Document Loaders
- Text Splitters
- Embedding Models
- Vector Stores
- Retrievers
- Output Parsers

These are plug-and-play components for building any LLM application.

---

## ðŸ§ª Code Examples
### 1. Simple LLM App
- User inputs a topic.
- Prompt created â†’ sent to LLM â†’ Response displayed.

### 2. PDF Reader App
- Load documents
- Split text
- Generate embeddings
- Store in vector database
- Retrieve relevant chunks
- Query LLM with the chunk

---

## ðŸ” Chains in LangChain
- Built-in abstraction to connect components.
- Example: **LLMChain** takes a prompt and an LLM â†’ automates prompt creation and response.

### RAG Example (Retriever QA Chain)
- Query â†’ Search vector DB â†’ Fetch relevant content â†’ Send to LLM â†’ Get answer.
- Simplifies the entire **Retrieval Augmented Generation (RAG)** process.

### Other Chain Types
- **Sequential Chain**: Multiple LLM chains in sequence.
- **SQL/Math/API Chains**: Specialized chains for common AI workflows.

---

## âš ï¸ Problem: Too Many Chains
### âŒ Challenges
1. Codebase became large and difficult to maintain.
2. Hard for new developers to know which chain to use.

### âš™ï¸ Root Cause
- Components were not standardized.
- LLMs used `.predict()`, prompts used `.format()`, retrievers used `.get_relevant_documents()`.
- Manual wiring needed â†’ explosion of custom chains.

---

## âœ… Solution: Standardization via Runnables
### ðŸ§± What are Runnables?
- **Units of work** with common interfaces.
- Methods:
  - `invoke()` â†’ Single input
  - `batch()` â†’ Multiple inputs
  - `stream()` â†’ Streamed outputs

- Like Lego blocks:
  - Consistent interface
  - Can be connected
  - Composite chains behave like individual blocks

---

## ðŸ‘¨â€ðŸ’» Demo: Building Runnables from Scratch
### Step 1: Dummy Components
- **Fake LLM Class** with `.predict()`
- **Prompt Template** with `.format()`

### Step 2: Combine Manually
- Create prompt â†’ format â†’ send to LLM â†’ get response

### Step 3: LLMChain Class
- Automates step above
- Limitation: Cannot scale to multi-step workflows

### Step 4: Abstract Runnable Class
- Create a base `Runnable` class with `invoke()` method.
- Force all components to implement `invoke()`.
- Add deprecation warnings for `.predict()`/`.format()`.

### Step 5: RunnableConnector
- Accepts list of runnables.
- Connects output of one to input of the next.
- Enables true **chain of components**.

---

## ðŸ”— Advanced Chaining
### Example: Joke Generator & Explainer
- Chain 1: Generate joke from topic
- Chain 2: Explain the joke
- Final Chain: Input â†’ Output (Explanation of joke)

### Benefits:
- No need to write new code for each use-case
- Just plug different prompt templates and LLMs

---

## ðŸ§  Internal Structure of LangChain
- Actual LangChain classes like `ChatOpenAI` inherit from abstract `Runnable`
- Demonstrates that LangChain uses the same fundamental structure as demoed.

---

## ðŸŽ¯ Conclusion
- Runnables solve the standardization problem.
- They make chaining components modular and scalable.
- Next video will explore actual LangChain `Runnable` classes.
- Encouragement to explore, build, and subscribe for deeper understanding.

---

> **ðŸš€ Key Takeaway:** Runnables are the backbone of LangChain's modern architectureâ€”standardized, composable, and reusable units that power AI workflows.

